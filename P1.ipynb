{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Rafael Roismann\n",
    "\n",
    "Nome: Rafael Curie Raiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "/Users/Rafa/Insper/2 Semestre/CDados/Projeto-01\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Classificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Um livro para ler e jogar fora e sem comentar ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Varios personagens sem desfecho, final sem pé ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Realmente. Deixou muito a desejar. Esperei um ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amei o livro inteiro, mas confesso que o final...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A tradução é péssima e diferente do original. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem  Classificacao\n",
       "0  Um livro para ler e jogar fora e sem comentar ...              1\n",
       "1  Varios personagens sem desfecho, final sem pé ...              1\n",
       "2  Realmente. Deixou muito a desejar. Esperei um ...              1\n",
       "3  amei o livro inteiro, mas confesso que o final...              1\n",
       "4  A tradução é péssima e diferente do original. ...              0"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel('dados_treino.xlsx')\n",
    "train.head(5)\n",
    "\n",
    "#train.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Classificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O que foi isto que recebi aqui em casa, mas di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O livro é uma mera propagando de leitura dinâm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A história pode ser boa, a leitura é muito can...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Achei que o livro mostra apenas oque o senso c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Não gostei muito do livro, ele é todo escrito ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem  Classificacao\n",
       "0  O que foi isto que recebi aqui em casa, mas di...              0\n",
       "1  O livro é uma mera propagando de leitura dinâm...              1\n",
       "2  A história pode ser boa, a leitura é muito can...              1\n",
       "3  Achei que o livro mostra apenas oque o senso c...              1\n",
       "4  Não gostei muito do livro, ele é todo escrito ...              1"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel('dados_teste.xlsx')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo foi criado um classificador segundo a teoria de probabilidade de *Naive Bayes*, nessa classificação foram utilizados os dois critérios abaixo para a classificação das frases:\n",
    "\n",
    "* **Critica sobre conteúdo do livro:** Dentro do escopo de nossa análise, todos os comentários que mencionam o autor da obra ou oferecem alguma forma de avaliação em relação ao seu conteúdo no livro foram cuidadosamente categorizados sob a classificação '1'. Essa classificação abrange uma ampla gama de comentários que exploram diversos aspectos da obra, desde a qualidade da narrativa até as críticas construtivas e as opiniões pessoais dos leitores. Ao examinarmos os comentários, consideramos não apenas as observações objetivas relacionadas ao livro, como sua trama, personagens e estilo de escrita, mas também as percepções subjetivas dos leitores em relação às expectativas que tinham antes de ler o livro e as eventuais frustrações que possam ter surgido durante a leitura.\n",
    "\n",
    "* **Criticas Sobre serviço da amazom e relacionados:** Esse item refere-se às frases previamente identificadas como comentários relativos ao serviço, ou a qualquer aspecto relacionado, como a entrega do produto ou a qualidade da tradução do livro. Essas frases abrangem as opiniões, observações e feedback dos clientes em relação à experiência que tiveram com o serviço em questão, bem como quaisquer serviços complementares, como a entrega ou a tradução do livro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1- Limpando o DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oi tudo bem\n"
     ]
    }
   ],
   "source": [
    "def cleanup(text):\n",
    "\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyz úáãâõôóàçé'+'abcdefghijklmnopqrstuvwxyz úáãâõôóàçé'.upper()\n",
    "    texto = []\n",
    "    for i in list(text):\n",
    "        if i in list(letras):\n",
    "            texto.append(i)\n",
    "    return ''.join(texto).lower()\n",
    "print(cleanup('oi! tudo bem?'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Fitrando as frases\n",
    "\n",
    "Na seção abaixo, usaremos a função acima para limpar o Dataframe e filtramos cada frase de acordo com sua classificação em relação a classificação pré definida anterioremnte, o Target do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['um', 'livro', 'para', 'ler', 'e', 'jogar', 'fora', 'e', 'sem', 'comentar']\n"
     ]
    }
   ],
   "source": [
    "# Criando as listas que armazenarão as palavras das frases nos respectivos grupos\n",
    "\n",
    "# Grupo 0 - Críticas sobre conteúdo do livro\n",
    "list_conteudo = []\n",
    "# Grupo 1 - Criticas Sobre serviço da amazom e relacionados\n",
    "list_servico = []\n",
    "\n",
    "for i in range(0,300):\n",
    "\n",
    "    # Pegar cada frase dentro do DataFrame e fazer a limpeza e transformar cada palavra em um valor de uma lista \n",
    "    list_palavra = cleanup(train.Mensagem[i]).split()\n",
    "    if train.Classificacao[i] == 0:    # Caso não seja classificado como críticas sobre o conteúdo do livro\n",
    "        for j in list_palavra:            \n",
    "            list_servico.append(j)\n",
    "\n",
    "    if train.Classificacao[i] == 1:    # Caso não seja classificado como críticas sobre o conteúdo do livro\n",
    "        for j in list_palavra:\n",
    "            list_conteudo.append(j)\n",
    "            \n",
    "# list_conteudo = [i for i in list_conteudo if i not in ['do', 'e', 'a', 'o', 'não', 'um', 'que']]\n",
    "# list_servico = [i for i in list_conteudo if i not in ['do', 'e', 'a', 'o', 'não', 'um', 'que']]\n",
    "print(list_conteudo[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Criando a segunda limpagem dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Criando um pd.Series e criando a tabela de frequência absoluta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando um pd.Series com as palavras classificadas como ***críticas ao livro*** e criando a sua respectiva tabela de frequência absoluta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "de       370\n",
       "o        349\n",
       "e        346\n",
       "que      343\n",
       "a        307\n",
       "não      251\n",
       "livro    221\n",
       "é        169\n",
       "um       165\n",
       "do       142\n",
       "dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardando as palavras em um pd.Series\n",
    "serie_conteudo = pd.Series(list_conteudo)\n",
    "# Tabela de frequência absoluta\n",
    "tabela_conteudo = serie_conteudo.value_counts()\n",
    "tabela_conteudo.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando um pd.Series com as palavras classificadas como ***críticas sobre o serviço da amazom e relacionados*** e criando a sua respectiva tabela de frequência absoluta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "o        174\n",
       "a        171\n",
       "de       159\n",
       "que      146\n",
       "e        144\n",
       "não       86\n",
       "livro     68\n",
       "com       64\n",
       "em        61\n",
       "do        53\n",
       "dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardando as palavras em um pd.Series\n",
    "serie_servico = pd.Series(list_servico)\n",
    "\n",
    "# Tabela de frequência absoluta\n",
    "tabela_servico = serie_servico.value_counts()\n",
    "tabela_servico.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando um pd.series com todas as palavras e criando a sua tabela de frequência absoluta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6863264020163831 0.3136735979836169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "de       0.033333\n",
       "o        0.032955\n",
       "e        0.030876\n",
       "que      0.030813\n",
       "a        0.030120\n",
       "não      0.021235\n",
       "livro    0.018210\n",
       "é        0.013926\n",
       "um       0.013674\n",
       "do       0.012287\n",
       "dtype: float64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Todas as palavras dos comentários\n",
    "total_palavras = list_conteudo + list_servico\n",
    "palavras_unicas = len(set(total_palavras))\n",
    "\n",
    "# Guardando as palavras em um pd.Series\n",
    "serie_total = pd.Series(total_palavras)\n",
    "print(len(serie_conteudo)/len(serie_total), len(serie_servico)/len(serie_total) )\n",
    "# Tabela de frequência absoluta\n",
    "tabela_total = serie_total.value_counts(True)\n",
    "tabela_total.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "print([1,2,3,4]+[3,4,5,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quanto % dos conteudos acertou 93.2%\n",
      "quanto % dos servicos acertou 88.9%\n",
      "quanto % dos conteudos eram realmete conteudos 95.77%\n",
      "quanto % dos servicos eram realmete servicos 82.76%\n",
      "quanto % dos chutes estavam certos 92.0%\n"
     ]
    }
   ],
   "source": [
    "def testar():\n",
    "    acerto_Cont = 0\n",
    "    erros_Cont = 0\n",
    "    acerto_Serv = 0\n",
    "    erros_Serv = 0\n",
    "    lenlist_servico = len(list_servico)\n",
    "    lenlist_conteudo = len(list_conteudo)\n",
    "    for i in range(200):\n",
    "        frase = cleanup(test.Mensagem[i])\n",
    "        vdd = test.Classificacao[i] # verdadeira classificação\n",
    "        probServ = len(list_servico)/len(total_palavras) # probabilidade inicial de ser serviço\n",
    "        probCont = len(list_conteudo)/len(total_palavras) # probabilidade inicial de ser conteudo\n",
    "        lista_frase = frase.split()\n",
    "        for palavra in lista_frase:\n",
    "            try:\n",
    "                contagemServ_palavra = tabela_servico[palavra] \n",
    "            except:\n",
    "                contagemServ_palavra = 0 # caso a palavra não esteja na tabela\n",
    "            try:\n",
    "                contagemCont_palavra = tabela_conteudo[palavra]\n",
    "            except:\n",
    "                contagemCont_palavra = 0 # caso a palavra não esteja na tabela\n",
    "\n",
    "            prob_servico = (contagemServ_palavra+1)/(lenlist_servico+palavras_unicas) # Suavizador Laplace\n",
    "            prob_conteudo = (contagemCont_palavra+1)/(lenlist_conteudo+palavras_unicas )\n",
    "\n",
    "            probServ *= prob_servico # Multiplicando as probabilidades\n",
    "            probCont *= prob_conteudo\n",
    "            if probServ == 0 or probCont == 0: # Caso a multiplicacao seja tão pequena que o computador não consiga calcular, ele para de calcular e faz o chute\n",
    "                chute = not probServ > probCont \n",
    "                break\n",
    "        probCont *=1.074\n",
    "        chute = not probServ > probCont # Verificando qual probabilidade é maior\n",
    "        if chute == vdd:\n",
    "            if vdd:  \n",
    "                acerto_Cont += 1\n",
    "            else:\n",
    "                acerto_Serv += 1\n",
    "        else:\n",
    "            if vdd:\n",
    "                erros_Serv += 1\n",
    "            else:\n",
    "                erros_Cont += 1\n",
    "    precisao_conteudo = acerto_Cont/(acerto_Cont+erros_Cont)\n",
    "    precisao_servico = acerto_Serv/(acerto_Serv+erros_Serv)\n",
    "    RealCont = acerto_Cont / (acerto_Cont + erros_Serv) \n",
    "    ReaclServ = acerto_Serv / (acerto_Serv+erros_Cont)\n",
    "    accuracy = (acerto_Cont + acerto_Serv) / 200\n",
    "    print(f\"quanto % dos conteudos acertou {round(precisao_conteudo, 3)*100}%\")\n",
    "    print(f\"quanto % dos servicos acertou {round(precisao_servico, 3)*100}%\")\n",
    "    print(f\"quanto % dos conteudos eram realmete conteudos {round(RealCont, 4)*100}%\")\n",
    "    print(f\"quanto % dos servicos eram realmete servicos {round(ReaclServ, 4)*100}%\")\n",
    "    print(f\"quanto % dos chutes estavam certos {round(accuracy, 3)*100}%\")\n",
    "\"\"\"\n",
    "melhor = 0\n",
    "melhor_alpha = 0\n",
    "for i in range(900, 1200):\n",
    "    alpha = i/1000\n",
    "    accuracy = testar(alpha)\n",
    "    if accuracy > melhor:          # encontrando o melhor alpha. melhor encontrado = 1.074\n",
    "        melhor = accuracy        \n",
    "        melhor_alpha = alpha\n",
    "print(melhor, melhor_alpha)        \"\"\"\n",
    "testar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Coluna 'Type'\n",
    "\n",
    "Criando a coluna ***Type*** responsável por guardar as classificações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classifica(frase):\n",
    "    palavras_unicas = len(set(total_palavras))\n",
    "    probServ = 1\n",
    "    probCont = 1\n",
    "    lista_frase = frase.split()\n",
    "    lenlist_servico = len(list_servico)\n",
    "    lenlist_conteudo = len(list_conteudo)\n",
    "    for palavra in lista_frase:\n",
    "        contagemServ_palavra = tabela_servico[palavra] if palavra in list_servico else 0\n",
    "        contagemCont_palavra = tabela_conteudo[palavra] if palavra in list_conteudo else 0\n",
    "        prob_servico = (contagemServ_palavra+1)/(lenlist_servico+palavras_unicas) # Suavizador Laplace\n",
    "        prob_conteudo = (contagemCont_palavra+1)/(lenlist_conteudo+palavras_unicas )\n",
    "        probServ *= prob_servico\n",
    "        probCont *= prob_conteudo\n",
    "        if probServ == 0 or probCont == 0:\n",
    "            chute = not probServ > probCont\n",
    "            return chute\n",
    "            \n",
    "    return not probServ > probCont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test['Type'] = [Classifica(test['Mensagem'][i]) for i in range(200)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('servico', 'alta')\n"
     ]
    }
   ],
   "source": [
    "def ClassificaFrase(frase):\n",
    "    palavras_unicas = len(set(total_palavras))\n",
    "    probServ = 1\n",
    "    probCont = 1\n",
    "    lista_frase = frase.split()\n",
    "    lenlist_servico = len(list_servico)\n",
    "    lenlist_conteudo = len(list_conteudo)\n",
    "    for palavra in lista_frase:\n",
    "        contagemServ_palavra = tabela_servico[palavra] if palavra in list_servico else 0\n",
    "        contagemCont_palavra = tabela_conteudo[palavra] if palavra in list_conteudo else 0\n",
    "        prob_servico = (contagemServ_palavra+1)/(lenlist_servico+palavras_unicas) # Suavizador Laplace\n",
    "        prob_conteudo = (contagemCont_palavra+1)/(lenlist_conteudo+palavras_unicas )\n",
    "        probServ *= prob_servico\n",
    "        probCont *= prob_conteudo\n",
    "        if probServ == 0 or probCont == 0:\n",
    "            chute = not probServ > probCont\n",
    "            return chute, 2\n",
    "    chute = not probServ > probCont\n",
    "    if chute:\n",
    "        confianca = probServ/probCont\n",
    "        if confianca < 0.2: confianca = 'alta'\n",
    "        elif confianca < 0.8: confianca = 'media'\n",
    "        else: confianca = 'baixa'\n",
    "        return 'conteudo', confianca\n",
    "    else:\n",
    "        confianca = probCont/probServ\n",
    "        if confianca < 0.2: confianca = 'alta'\n",
    "        elif confianca < 0.8: confianca = 'media'\n",
    "        else: confianca = 'baixa'\n",
    "        return 'servico', confianca\n",
    "print(ClassificaFrase('a capa do livro veio amassada'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/Rafa/Insper/2 Semestre/CDados/Projeto-01/P1.ipynb Cell 37\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Rafa/Insper/2%20Semestre/CDados/Projeto-01/P1.ipynb#X51sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m lis\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lis' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CONSIDEROU mais de duas categorias na variável Target e INCREMENTOU a quantidade de notícias, mantendo pelo menos 250 notícias por categoria (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* Para Target com duas categorias: CRIOU pelo menos quatro categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item Qualidade do Classificador a partir de novas separações das Notícias entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
